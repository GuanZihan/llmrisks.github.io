<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Risks (and Benefits) of Generative AI and Large Language Models</title>
    <link>https://llmrisks.github.io/post/</link>
    <description>Recent content in Posts on Risks (and Benefits) of Generative AI and Large Language Models</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>evans@virginia.edu (David Evans)</managingEditor>
    <webMaster>evans@virginia.edu (David Evans)</webMaster>
    <lastBuildDate>Mon, 11 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://llmrisks.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Week 2: Alignment</title>
      <link>https://llmrisks.github.io/week2/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week2/</guid>
      <description>(see bottom for assigned readings and questions)
Table of Contents  (Monday, 09/04/2023) Introduction to Alignment  Introduction to AI Alignment and Failure Cases  Discussion Questions   The Alignment Problem from a Deep Learning Perspective  Group of RL-based methods Group of LLM-based methods Group of Other ML methods     (Wednesday, 09/06/2023) Alignment Challenges and Solutions  Opening Discussion Introduction to Red-Teaming  In-class Activity (5 groups) How to use Red-Teaming?</description>
    </item>
    
    <item>
      <title>Week 3: Prompting and Bias</title>
      <link>https://llmrisks.github.io/week3/</link>
      <pubDate>Wed, 06 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week3/</guid>
      <description>Readings   (for Monday) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. 2022.
  (for Wednesday) Myra Cheng, Esin Durmus, Dan Jurafsky. Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models. ACL 2023.
  Optional Additional Readings Background:
 Lilian Weng, Prompting Engineering. March 2023. Miles Turpin, Julian Michael, Ethan Perez, Samuel R.</description>
    </item>
    
    <item>
      <title>Week 1: Introduction</title>
      <link>https://llmrisks.github.io/week1/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week1/</guid>
      <description>(see bottom for assigned readings and questions)
Attention, Transformers, and BERT Monday, 28 August
Transformers1 are a class of deep learning models that have revolutionized the field of natural language processing (NLP) and various other domains. The concept of transformers originated as an attempt to address the limitations of traditional recurrent neural networks (RNNs) in sequential data processing. Here&amp;rsquo;s an overview of transformers&#39; evolution and significance.
Background and Origin RNNs2 were one of the earliest models used for sequence-based tasks in machine learning.</description>
    </item>
    
    <item>
      <title>Github Discussions</title>
      <link>https://llmrisks.github.io/discussions/</link>
      <pubDate>Fri, 25 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/discussions/</guid>
      <description>Everyone should have received an invitation to the github discussions site, and be able to see the posts there and submit your own posts and comments. If you didn&amp;rsquo;t get this invitation, it was probably blocked by the email system. Try visiting:
https://github.com/orgs/llmrisks/invitation
(while logged into the github account you listed on your form).
Once you&amp;rsquo;ve accepted the invitation, you should be able to visit https://github.com/llmrisks/discussions/discussions/2 (the now-finalized discussion post for Week 1), and contribute to the discussions there.</description>
    </item>
    
    <item>
      <title>Class 0: Getting Organized</title>
      <link>https://llmrisks.github.io/class0/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/class0/</guid>
      <description>I&amp;rsquo;ve updated the Schedule and Bi-Weekly Schedule based on the discussions today.
The plan is below:
  Week Lead Team Blogging Team Everyone Else     Two Weeks Before  Come up with idea for the week and planned readings, send to me by 5:29pm on Tuesday (2 weeks - 1 day before)  -  -    Week Before  Post plan and questions in github discussions by no later than 9am Wednesday; prepare for leading meetings   Prepare plan for blogging (how you will divide workload, collaborative tools for taking notes and writing)   Read/do materials and respond to preparation questions in github discussions (by 5:29pm Sunday)    Week of Leading Meetings  Lead interesting, engaging, and illuminating meetings!</description>
    </item>
    
    <item>
      <title>Updates</title>
      <link>https://llmrisks.github.io/updates/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/updates/</guid>
      <description>Some materials have been posted on the course site:
 Syllabus Schedule (you will find out which team you are on at the first class Wednesday) Readings and Topics (a start on a list of some potential readings and topics that we might want to cover)   
Dall-E Prompt: &#34;comic style drawing of a phd seminar on AI&#34;  </description>
    </item>
    
    <item>
      <title>Welcome Survey</title>
      <link>https://llmrisks.github.io/survey/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/survey/</guid>
      <description>Please submit this welcome survey before 8:59pm on Monday, August 21:
 https://forms.gle/dxhFmJH7WRs32s1ZA
 Your answers won&amp;rsquo;t be shared publicly, but I will use the responses to the survey to plan the seminar, including forming teams, and may share some aggregate and anonymized results and anonymized quotes from the surveys.</description>
    </item>
    
    <item>
      <title>Welcome to the LLM Risks Seminar</title>
      <link>https://llmrisks.github.io/welcome/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/welcome/</guid>
      <description>Full Transcript
 Seminar Plan The actual seminar won&amp;rsquo;t be fully planned by GPT-4, but more information on it won&amp;rsquo;t be available until later.
I&amp;rsquo;m expecting the structure and format to that combines aspects of this seminar on adversarial machine learning and this course on computing ethics, but with a topic focused on learning as much as we can about the potential for both good and harm from generative AI (including large language models) and things we can do (mostly technically, but including policy) to mitigate the harms.</description>
    </item>
    
  </channel>
</rss>
