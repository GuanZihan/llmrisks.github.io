+++
date = "13 Sep 2023"
draft = false
title = "Week 4: Capabilities of LLMs"
slug = "week4"
+++

# Readings

**Monday:**

1. Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, Xia Hu. [_Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond_](https://arxiv.org/abs/2304.13712). April 2023. [https://arxiv.org/abs/2304.13712](https://arxiv.org/abs/2304.13712). [[PDF](https://arxiv.org/pdf/2304.13712.pdf)]

2. OpenAI. [_GPT-4 Technical Report_](https://arxiv.org/abs/2303.08774). March 2023. [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774) [[PDF](https://arxiv.org/pdf/2303.08774.pdf)]

Optionally, also explore [https://openai.com/blog/chatgpt-plugins](https://openai.com/blog/chatgpt-plugins).

**Wednesday:**

3. Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, Vivek Natarajan. [_Towards Expert-Level Medical Question Answering with Large Language Models_](https://arxiv.org/abs/2305.09617)
[https://arxiv.org/abs/2305.09617](https://arxiv.org/abs/2305.09617) [[PDF](https://arxiv.org/pdf/2305.09617.pdf)]

Optional Readings:
- Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, Eric Horvitz. [_Capabilities of GPT-4 on Medical Challenge Problems_](https://arxiv.org/abs/2303.13375). March 2023. [https://arxiv.org/abs/2303.13375](https://arxiv.org/abs/2303.13375)
-  Travis Zack, Eric Lehman, Mirac Suzgun, Jorge A. Rodriguez, Leo Anthony Celi, Judy Gichoya, Dan Jurafsky, Peter Szolovits, David W. Bates, Raja-Elie E. Abdulnour, Atul J. Butte,  Emily Alsentzer. [_Coding Inequity: Assessing GPT-4â€™s Potential for Perpetuating Racial and Gender Biases in Healthcare_](https://www.medrxiv.org/content/10.1101/2023.07.13.23292577). July 2023. 
[https://www.medrxiv.org/content/10.1101/2023.07.13.23292577](https://www.medrxiv.org/content/10.1101/2023.07.13.23292577) &mdash; This article relates to the underlying biases in the models we talked about this week, but with an application that show clear potential harm resulting from these biases in the form if increased risk of medical misdiagnosis.

## Discussion for Monday: 

Everyone who is not in either the lead or blogging team for the week should post (in the comments below) an answer to at least one of the questions in this section, or a substantive response to someone else's comment, or something interesting about the readings that is not covered by these questions. Don't post duplicates - if others have already posted, you should read their responses before adding your own. Please post your responses to different questions as separate comments.

You should post your _initial_ response before 5:29pm on Sunday, September 17, but feel free (and encouraged!) to continue the discussion after that, including responding to any responses by others to your comments.

1. Based on the criterions shown in Figure 2 of [1], imagine a practical scenario and explain why you would choose or not choose using LLMs for your scenario.
2. Are plug-ins the future of AGI? Do you think that a company should only focus on building powerful AI systems that does not need any support from plug-ins, or they should only focus on the core system and involve more plug-ins into the ecosystem?

## Discussion for Wednesday:

You should post your _initial_ response to one of the questions below or something interesting related to the Wednesday readings before 5:29pm on Tuesday, September 19.

1. What should we do before deploying LLMs in medical diagnosis applications? What (if any) regulations should control or limit how they would be used?

2. With LLMs handling sensitive medical information, how can patient privacy and data security be maintained? What policies and safeguards should be in place to protect patient data?

3. The paper discusses the progress of LLMs towards achieving physician-level performance in medical question answering. What are the potential implications of LLMs reaching or surpassing human expertise in medical knowledge?

4. The paper mentions the importance of safety and minimizing bias in LLM-generated medical information, and the [optional reading](https://www.medrxiv.org/content/10.1101/2023.07.13.23292577) reports on some experiments that show biases in GPT's medical diagnoses. Should models be tuned to ignore protected attributes? Should we prevent models from being used in medical applications until these problems can be solved?
