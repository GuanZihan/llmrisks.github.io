<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Risks (and Benefits) of Generative AI and Large Language Models</title>
    <link>https://llmrisks.github.io/</link>
    <description>Recent content on Risks (and Benefits) of Generative AI and Large Language Models</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>evans@virginia.edu (David Evans)</managingEditor>
    <webMaster>evans@virginia.edu (David Evans)</webMaster>
    <lastBuildDate>Thu, 17 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://llmrisks.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Welcome Survey</title>
      <link>https://llmrisks.github.io/survey/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/survey/</guid>
      <description>Please submit this welcome survey before 8:59pm on Monday, August 21:
 https://forms.gle/dxhFmJH7WRs32s1ZA
 Your answers won&amp;rsquo;t be shared publicly, but I will use the responses to the survey to plan the seminar, including forming teams, and may share some aggregate and anonymized results and anonymized quotes from the surveys.</description>
    </item>
    
    <item>
      <title>Welcome to the LLM Risks Seminar</title>
      <link>https://llmrisks.github.io/welcome/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/welcome/</guid>
      <description>Full Transcript
 Seminar Plan The actual seminar won&amp;rsquo;t be fully planned by GPT-4, but more information on it won&amp;rsquo;t be available until later.
I&amp;rsquo;m expecting the structure and format to that combines aspects of this seminar on adversarial machine learning and this course on computing ethics, but with a topic focused on learning as much as we can about the potential for both good and harm from generative AI (including large language models) and things we can do (mostly technically, but including policy) to mitigate the harms.</description>
    </item>
    
    <item>
      <title>Schedule</title>
      <link>https://llmrisks.github.io/schedule/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/schedule/</guid>
      <description>The schedule details will be filled in as the semester progresses (and future weeks are subject to change, but as much as is known is documented here).
  Week Lead Team Blog Team Topic     1: 2/4 Feb Dave Introduction; Views of Technology   2: 9/11 Feb 14 Race Against Technology, Intro, Ch 1    3: 16/18 Feb 25 Race Against Technology, Ch 2&amp;ndash;3    4: 23/25 Feb 31 Race Against Technology, Ch 4&amp;ndash;5    5: 2/4 Mar 42 Deepfakes    6: 11 Mar Dave Project Ideas Discussion (Break day 9 Mar)    7: 16/18 Mar 53 Social Scoring    19 March Project Idea Proposals Due (4:59pm)    8: 23/25 Mar 14 UI Design Ethics    9: 30 Mar/1 Apr 25 Recommendations and Manipulation    10: 6/8 Apr 31 Privacy and Surveillance    11: 13 Apr Guest: Saiph Savage Crowd Workers (Break day 15 Apr)    12: 20/22 Apr 42 Centralization and Anti-trust    13: 27/29 Apr 53 End-to-end Encryption    14: 4/6 May Everyone Project Presentations     Typical Biweekly Schedule    Week Monday Tuesday Wednesday Thursday Sunday      Week N (led by team E)   Team A: have initial idea ready for Week N+1</description>
    </item>
    
  </channel>
</rss>
